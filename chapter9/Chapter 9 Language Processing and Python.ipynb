{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.1 Grammatical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORTH  => chased\n",
      "REL   => chase\n",
      "AGT   => k\n",
      "PAT   => l\n"
     ]
    }
   ],
   "source": [
    "# CAT: grammatical category\n",
    "# ORTH: orthography -- spelling\n",
    "# REF: reference\n",
    "# REL: relationship\n",
    "\n",
    "kim = {'CAT': 'NP', 'ORTH': 'Kim', 'REF': 'k'}\n",
    "\n",
    "chase = {'CAT': 'V', 'ORTH': 'chased', 'REL': 'chase'}\n",
    "\n",
    "lee = {'CAT': 'NP', 'ORTH': 'Lee', 'REF': 'l'}\n",
    "\n",
    "sent = \"Kim chased Lee\"\n",
    "\n",
    "tokens = sent.split()\n",
    "\n",
    "\n",
    "def lex2fs(word):\n",
    "    for fs in [kim, lee, chase]:\n",
    "        if fs['ORTH'] == word:\n",
    "            return fs\n",
    "\n",
    "subj, verb, obj = lex2fs(tokens[0]), lex2fs(tokens[1]), lex2fs(tokens[2])\n",
    "\n",
    "verb['AGT'] = subj['REF'] # agent of 'chase' is Kim\n",
    "verb['PAT'] = obj['REF'] # patient of 'chase' is Lee\n",
    "\n",
    "for k in ['ORTH', 'REL', 'AGT', 'PAT']: # check featstruct of 'chase'\n",
    "    print(\"%-5s => %s\" % (k, verb[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agreement for CFG\n",
    "\n",
    "    S -> NP_SG VP_SG\n",
    "    S -> NP_PL VP_PL\n",
    "    NP_SG -> Det_SG N_SG\n",
    "    NP_PL -> Det_PL N_PL\n",
    "    VP_SG -> V_SG\n",
    "    VP_PL -> V_PL\n",
    "    \n",
    "    Det_SG -> 'this'\n",
    "    Det_PL -> 'these'\n",
    "    N_SG -> 'dog'\n",
    "    N_PL -> 'dogs'\n",
    "    V_SG -> 'runs'\n",
    "    V_PL -> 'run'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.2 Processing Feature Structures\n",
    "\n",
    "    Features as graph or knowledge base -- union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.3 Extending a Feature-Based Grammar\n",
    "\n",
    "\n",
    "    Subcategorization -- Generalized Phrase Structure Grammar (GPSG)\n",
    "    \n",
    "    Heads Revisted\n",
    "    \n",
    "    Auxiliary Verbs and Inversion\n",
    "    \n",
    "    Unbounded Dependency Constructions\n",
    "    \n",
    "    Case and Genders in German\n",
    "\n",
    "### Summary: many of the generalised CFG is feature based and in old days the machine learning is also refered to as feature engineering. It is still the case now for deep learning, however, less at the feature level more from the model level with induction bias. There is no reason to not use the old techniques since they bring more information to the 'model' or at least more easier for 'model' to learn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
